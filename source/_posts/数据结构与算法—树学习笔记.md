---
title: 数据结构之树学习小结
date: 2020-05-20 13:33:29
tags: [数据结构,笔记]
---

此系列是我数据结构的学习笔记，观看视频课程，网上有很全面的笔记了，节约时间，细节没有再展开。

本篇博客分享主题：「树」，简单总结一下近期学的二叉搜索树、平衡二叉搜索树、红黑树，重点介绍二叉搜索树。

## 基本认识

二叉搜索树(Binary Search Tree),又叫做二叉查找树、二叉排序树。

- 任意一个节点的值都`大于`其`左子树`所有节点的值。
- 任意一个节点的值都`小于`其`右子树`所有节点的值。
- 它的`左右子树`也是一颗二叉搜索树。

![一棵二叉搜索树（BST）](/images/image-20200520151358919.png)

为什么要引入二叉搜索树，需求是什么？

+ 在乱序数组中插入元素，搜索操作平均时间复杂度O(n)，插入操作复杂度O(1)

+ 排好序的数组，二分搜索，最坏时间复杂度O(logn),但插入、删除操作平均复杂度是O(n)

+ 使用二叉搜索树，添加、删除、搜索的最坏时间复杂度均可优化至：`O(logn)`））（更准确得说是O(h),h为树高）

而后面学到的平衡二叉搜索树（AVL）、红黑树（Red Black tree）都是特殊的二叉搜索树，它们主要是为了解决BST太不平衡时效率退化的问题，只不过为了维持二叉树的(相对)平衡，它们有各自附加的要求。总的来说，添加、删除节点这两个基本操作都是一样的，只不过对于AVL和RBT来说，在添加或删除元素之后，可能会破坏树原来的性质，所以需要一些额外的操作（对于AVL来说是旋转，对于RBT来说是着色和旋转）来维持树的性质，以达到更好的性能。

退化成链表的二叉搜索树时间复杂度就变成了O(n)，那么AVL和RBT是怎么优化的呢？
AVL树的节点除了维护节点的左右父节点的指针之外，还会维护此节点的高度，AVL树规定每个节点的平衡因子只可能是1，0，-1，否则，称之为失衡。添加和删除节点后可能会导致失衡，我们就做一些额外的操作让它重复恢复平衡就行,具体又分为LL、RR和LR、RL的旋转情况，本文不再展开。

![上面那棵BST等价的AVL树](/images/image-20200520151453143.png)



而红黑树的节点除了维护节点的左右父节点的指针之外，还会维护此节点的颜色,红黑树的性质比起AVL更加复杂：

1、节点是RED或者BLACK
2、根节点是BLACK
3、叶子节点（外部节点，空节点）都是BLACK
4、RED节点的子节点都是BLACK

- RED节点的parent都是BLACK
- 从根节点到叶子节点的所有路径上不能有2个连续的RED节点

5、从任意节点到叶子节点的所有路径都包含相同数目的BLACK节点。

![上面那棵BST等价的红黑树](/images/image-20200520151531566.png)



## BST的插入删除操作

插入操作比较简单，只需要不断将要插入结点的值和当前工作节点比较，如果待插入节点的值比当前节点的值大，就往左走，否则就往右走，直到工作节点为空，就确定了插入位置。

查找的操作也类似。

删除需要考虑三种情况：度为0、1、2。 

度为2： 令后继结点的元素值覆盖删除结点，然后删除后继节点，后继节点的度必为0/1，所以就转化成了下面的两种情况 (ps.取前驱节点替代也可以）
度为1： 使删除结点的父节点指向删除结点的子结点，注意删除的是根节点的特殊情况
度为0： 直接删除，注意删除的是根节点的特殊情况



## 常用方法

### 遍历(适用所有二叉树)

1. 前序遍历(Preorder)，访问顺序： `根节点` -> `前序遍历左子树` -> `前序遍历右子树`
递归实现。
   
2. 中序遍历(Inorder)，访问顺序：`中序遍历左子树` -> `根节点` -> `中序遍历右子树`

   中序遍历的结果是有序的，因为根据BST的定义，左<中<右。

3. 后序遍历(Postorder)，访问顺序：`后序遍历左子树` -> `后序遍历右子树` -> `根节点`

4. 层序遍历(Level Order)，访问顺序：`从上到下`，`从左到右`依次访问节点。

对于前中后序遍历来说，既可以用递归实现，还可以非递归实现(栈)。

参考我的其他博客：

[前序遍历的非递归实现]([https://hfq123.github.io/2020/04/21/%E3%80%90%E6%AF%8F%E6%97%A5%E6%9B%B4%E6%96%B0%E3%80%91%E7%AE%97%E6%B3%95%E9%A2%98/#%E9%A2%984-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%89%8D%E5%BA%8F%E9%81%8D%E5%8E%86%EF%BC%88%E9%9D%9E%E9%80%92%E5%BD%92%E6%96%B9%E6%B3%95%EF%BC%89](https://hfq123.github.io/2020/04/21/[每日更新]算法题/#题4-二叉树的前序遍历（非递归方法）))

[后序遍历的非递归实现](https://hfq123.github.io/2020/04/21/[每日更新]算法题/#题1-非递归二叉树后序遍历)

![一棵二叉树的遍历结果](/images/image-20200411002614229.png)



### 求前驱节点和后续节点

一个节点的前驱节点和后续节点分别指的是树的中序遍历结果中这个节点的前一个结点和后一个结点，计算前驱节点的思路如下：

+ 如果此节点有左子树，必定有前驱节点，前驱节点=node.left.right...right
+ 如果此节点没有左子树，但是有根节点，则可能有前驱节点，前驱节点=node.parent.parent...直到当前结点是父节点的左孩子。
+ 否则，返回null

后续节点同理。



## 设计思想

这一部分，简单谈一谈设计BST类代码时候的设计模式，可供参考，把代码写的优雅一点。

### 策略模式

从二叉搜索树的定义来看，涉及到比较操作，所以二叉搜索树存储的元素必须具备可比较性。

一方面，我们可以规定节点元素必须是**可比较**的，也就是使节点元素的类实现Comparable接口，里面实现compareTo方法，又可以在BST类中加入一个**外部比较器**，可以让调用者自行决定使用什么比较方法来比较元素大小。
详情不再展开，参考[比较器comparable与comparator的使用](https://www.cnblogs.com/qq1083735206/p/6242205.html)



### 模板方法模式

BST类是父类，AVL和RBT是子类。我们前面说了，在BST中的插入删除方法，只需要做基本操作，而AVL和RBT的插入删除操作之后，还需要做一些额外操作来维持树的性质，所以在设计BST这一个父类的时候，将add()和remove()方法（分别用于插入和删除结点）作为模板方法，在两个方法的最后调用afterAdd()和afterRemove()作为“钩子”，在BST类中，afterAdd()和afterRemove()这两个方法里什么都不做，而AVL和RBT子类重写它们，里面写插入/删除节点后维持树性质的代码。

这样一来，AVL和RBT这两个子类，就可以重用基本操作部分的代码。



## 性能比较

参考[动态查找树比较](https://www.iteye.com/topic/614070)。

BST效率总结： 查找最好时间复杂度O(logN)，最坏时间复杂度O(N)，和高度相关O(h)。

插入删除操作算法简单，时间复杂度与查找差不多。

 AVL效率总结： 查找的时间复杂度维持在O(logN)，不会出现最差情况

 AVL树在执行每个插入操作时最多需要1次旋转，其时间复杂度在O(logN)左右。

 AVL树在执行删除时代价稍大，可能造成O(logN)次旋转，执行每个删除操作的时间复杂度需要O(2logN)。

红黑树效率总结：

查找效率最好情况下时间复杂度为O(logN)，但在最坏情况下比AVL要差一些（因为树高可能比AVL高），但也远远好于BST。

插入和删除操作改变树的平衡性的概率要远远小于AVL（RBT不是高度平衡的）。因此需要的旋转操作的可能性要小，而且一旦需要旋转，插入一个结点最多只需要旋转2次，删除最多只需要旋转3次(小于AVL的删除操作所需要的旋转次数)。虽然变色操作的时间复杂度在O(logN)，但是实际上，这种操作由于简单所需要的代价很小。

![AVL树和红黑树性能对比以及选择图解](/images/image-20200520155601295.png)



## 个人总结

BST和AVL树和红黑树的基础，在理想情况下，它的查找、插入、删除的时间复杂度是O(logN)，但是在一些情况下，其时间复杂度会退化，极端情况下退化成链表，总的来说，BST查找、插入、删除的时间复杂度是和其整体高度正相关的。所以，AVL为了不让BST由于高度失衡而导致时间复杂度退化，就规定了平衡因子的概念，它的查找操作完全和BST一样，插入删除操作之后如果导致树失衡会做旋转操作使得恢复平衡，这样就严格控制了其平衡性（也就是控制了树的高度），所以查找、插入、删除三个操作的时间复杂度都能稳定维持在O(logN）。这里我们还有必要了解一些AVL插入和删除节点的细节:在AVL树插入节点只会造成1次旋转（单旋或双旋），而在AVL树删除节点可能会造成O(logN)次旋转（删除后，父节点失衡调整后导致其祖父节点直到根节点都失衡，都需要旋转）。

而红黑树相较于AVL树来说，对于树的平衡要求没有AVL那么高（所以说，拥有同样多节点的树，红黑树可能比AVL树的树高更大），虽然在红黑树节点定义中，并没有看到关于高度的定义，只有颜色的定义，但是实际上只要满足了其五条要求（在插入删除节点后可能会破坏红黑树要求，所以要进行染色和旋转操作），最后构建出来的红黑树的高度就不会像BST那样有高度严重失衡的坏情况，事实上，红黑树的最长路径长度不超过最短路径长度的2倍，所以说其查找代价还是能基本维持在O(logN)，有时查找性能或许比AVL略逊色一点（因为其高度可能比AVL大），但是其RBT的删除操作代价要比AVL要好的多，删除一个结点最多只需要3次旋转操作。



## 推荐阅读

以下博文的笔记很详细，给出链接供查阅。

[小码哥《恋上数据结构与算法》笔记（八）：二叉搜索树](https://juejin.im/post/5dfc735ee51d45582d3405de)

[小码哥《恋上数据结构与算法》笔记（九）：平衡二叉搜索树（AVL）](https://juejin.im/post/5e057217f265da33d912ecfe)

[小码哥《恋上数据结构与算法》笔记（十）：B树](https://juejin.im/post/5e0aedb8f265da5d5e2419a1)

[小码哥《恋上数据结构与算法》笔记（十一）：红黑树](https://juejin.im/post/5e0da754f265da5d2202025a)

[为什么HashMap使用红黑树而不使用AVL树](https://blog.csdn.net/qq_41999455/article/details/95342982)



另外，推荐一个可以模拟各种树构建、删除过程的网页：

[构建各种树的可视化网页工具](http://520it.com/binarytrees/)

还有一个常用的树：哈夫曼树,参考：[哈夫曼树与哈夫曼编码](https://www.cnblogs.com/linfangnan/p/12593480.html)

